wir wollen fuer standard gp auf numerischen raeumen: https://arxiv.org/pdf/2103.16649.pdf
scaling auf den unit cube (offen: fixed oder nicht fixed nach initial design?)
gp optimized mit multistart? starting points lhs 2d

nur als fallback jitter

x = 0:10
y = runif(11, 0, 20)
task = TaskRegr$new("test", backend = data.table(x = x, y = y), target = "y")
d = 1
U = 10
L = 0
upper = (U-L)/sqrt(d)
lower = upper / 100
actually want lhs design for init of multistart
learner = lrn("regr.km", covtype = "matern5_2", upper = upper, lower = lower, multistart = 3L, optim.method = "BFGS")
learner$fallback = lrn("regr.km", covtype = "matern5_2", upper = upper, lower = lower, multistart = 3L, optim.method = "BFGS", nugget.stability = 10^-8)


asserts_bayesopt(inst, initdes, surrogate, acq, a_opt)

das initial design generieren sollte vielleicht doch in die instance
das passiert ja schon konfigurierbare logik.
instance$generate_design
vielleicht will man dafuer auch eine sublklasse MBOInstance? vielleicht aber
auch nicht und der code sollte in bbotk
vllt. initial design auch in OptimizerMBO

das errorhandling und stepping sollte woll in eine klasse
viellicht MBOStep oder MBOLoop
das hat dann subklassen fuer jedes verfahren?
das errorhandling passiert in der basisklasse, logging usw auch
eval_batch auch, und termination check auch

single step geht ueber teminator n_evals = 1, dann terminate clear wenn weiter

bayesopt_dictionary, properties: batch, single & multicrit

run_mbo_block(expr) {
   trycatch {
     eval(expr)
   ....
}

besser immer optimizermbo ableiten?

optimzer_mbo
  - my_asserts
  - mbo_loop_function. kann man auch ueberschreiben und komplett selber machen?
  - mbo_propose_step: abstract

test_OptimizerMbo works with different settings expand

document initial design random and you can supply your own

mbo_defaults, doc and links etc., default_surrogate

results_by_surrogate with eips

test_r6 --> inherits

deep clones

check return()

$setup was actually nice for OptimizerMBO design.
check if we use setup_acqfun and setup_acqopt that we can flawlessly switch between instances
maybe drop y_cols again and make ab, simply rely on tags in codomain

why does Acqf constructor get archive if we could use surrogate archive

check surrogate_max_to_min(codomain) for parEgo?

ParamSet --> ps

stop(.) period

check if tests use helpers

learner default mit evaluate wrappen? eher nicht weil das wird mit random propsal gecatched

Optimizer should infer properties from surrogate, acqf, acqo and loop

mlr3mbo yahpo gym benchmark

formats und printer definieren

dicts:
  acqf should get singlecrit multicrit tags
